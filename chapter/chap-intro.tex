\chapter{绪论}
神经网络处理器，是指具有模仿人的大脑判断能力和适应能力、可并行处理多种数据功能的处理器。相较于CPU、GPU，神经网络处理器结合了神经网络模型的数据局部性特点以及计算特性，进行存储体系以及专用硬件设计，从而具有更好的性能加速比以及计算功耗比。

从2008年起，中科院计算技术研究所智能处理器研究中心开展了寒武纪系列神经网络处理器的研发，这也是国际上首个深度学习处理器结构。当前寒武纪系列已包含3种原型处理器结构：DianNao，单核神经网络处理器结构；DaDianNao，面向超大规模神经网络的多核处理器结构；PuDianNao，面向多种机器学习算法。在若干代表性深度神经网络上的实验结果表明，DianNao的平均性能超过主流CPU核的100倍，但是面积仅为1/30而功耗则仅为1/5,效能提升可达3个数量级；DianNao的平均性能与主流GPU相当，但面积和功耗仅为主流GPU百分之一量级。2016年，中科院计算所的研究团队又提出了了深度学习指令集Cambrican，试图在更为泛化的层面来完成AI加速器的设计。

为了方便用户编程，减少开发难度，我们设计了一套包括库和编译器的软件，为了保证这套软件的正确性和可靠性，我们需要对其进行测验。然而，徒手检查代码工作量大，而仅靠随机生成的指令又无法覆盖到实际使用需求的指令序列，因此，设计一个能用于检测神经网络处理器编译器的测试框架势在必行。

本节，我们将先回顾软件验证的传统方法以及编译器的传统验证方法，比较神经网络处理器编译器以及传统编译器的不同，分析传统编译器验证的局限性，最后推导出神经网络处理器编译器验证框架的必要性。

\section{验证的传统方法}
\subsection{软件验证的传统验证方法}
随着计算机软件在一些关键领域，例如航空航天、军事武器以及其他对软件可靠性要求极为严格的领域应用越来越广泛，其复杂程度和功能越来越复杂，集成程度也越来越高。在这种情况下，人们对软件的正确性、可靠性、可靠安全性和保密性等可信性质给予了十分的关注，如何在软件的开发和运行中保证软件具有高可信性质也成为软件理论和技术的重要研究方向。

早期的验证方法分成黑盒测试和白盒测试，黑盒测试是指不考虑系统的内部结构，只按照规格说明测试已定义的功能，所以又被成为基于功能的测试。黑盒测试则将系统看成一个黑盒子，只关心系统的输入输出，所以测试方法的重点在于如何从输入域中选择待测的测试用例。黑盒测试的一般方法主要有：等价类划分（包括有效等价类和无效等价类）、边界值分析（包括有效边界内和边界外）、判定表（系统输入输出的有效组合）、因果图（系统输入输出的制约关系图）。

而白盒测试则是考虑系统的内部结构，重点测试系统的每一个动作是否符合定义，因此又称为基于结构的测试。白盒覆盖对测试用例的选择主要看是否能达到对系统内部结构的覆盖，有不同的多级覆盖准则：语句覆盖、判定覆盖、条件覆盖、判定——条件覆盖、路径覆盖等。

后来，随着软件验证领域的不断发展，验证理论也不断产生。又产生了如下几种软件测试方法。

基于模型的测试。测试用例的选择问题可以看做是从庞大的输入、状态组合中，搜寻那些可以发现错误的状态及组合。如果不适用抽象的手段，有效的测试是不可能达到的。模型化的方法被广泛应用于工程领域，模型是系统功能的形式化或半形化的表示，必须支持输入、状态系统组合的系统枚举，虽然不能产生所有的输入、状态组合，但是模型可以帮助实现这一目的。

错误驱动测试。功能测试仅能测试系统已实现功能的完备性，而对系统缺少的部分无能为力。在用户实际使用的过程中，会有大量的非法输入，此时系统表现如何，是否会崩溃，基于非法操作或错误的测试就是错误驱动测试。

回归测试。回归测试就是一个不断发现测试和不断改正错误的过程。由于程序的复杂性，各个模块及元素（变量、函数、类）之间存在着相关联性，所以对于改正的错误，还要进行在测试。一方面检查此错误是否真的被修改了，另一方面检查此错误修改是否引入了新的错误，这就需要将测过的样例拿来重新进行测试，这就是回归测试。

\subsection{编译器的传统验证方法}
编译器作为计算机软件中最基础的软件之一，与操作系统、数据库系统一起被列为构成计算机系统关键性基础设施。而编译器作为任何软件的产生器，它的安全性、可靠性和稳定性更是至关重要，特别是在那些软件的可靠性要求很高的特殊环境里面，我们必须保证编译器编译出来的代码是对程序源代码正确、真实的反应，保证编译器在编译过程中逻辑上正确性以及行为上的透明性。

编译器系统可信验证主要包括两方面，一个是编译器的逻辑正确性，即编译器编译的程序在逻辑上符合程序源代码的描述，与程序源代码的逻辑一致；另一方面是编译器的安全性和可靠性，这个指编译器在编译过程中不会人为地插入恶意代码，导致目标程序运行不可靠或者达到某些其他恶意的目的。

下面主要介绍编译器的逻辑正确性。

Leroy等人为C语言编译器提出了一种开发编译器以及在开发过程中形式化验证编译器可信性的方法，他们设计了一种叫作Coq proof assistant的工具，在开发编译器过程中验证该编译器是否是正确的。他们的方法侧重于对编译器后端（即中间语言到代码生成过程）的形式化验证，Sandrine等人扩充了Leroy等人的研究，也提出了一种形式化的C语言编译器可信验证方法，该方法支持C语言的一个子集的验证，而且它能够验证编译器的前端过程（即从源代码到中间语言转换过程）的正确性。

如果不能验证整体编译器的正确性，另一种思路则是对每一个编译步骤的正确性进行检查。翻译验证（translation validation）就是一种基于此思路的编译器正确验证方法，其目标是检查每一个编译步骤的结果，将其与源程序比较，检测可能存在的编译错误，该方法绕开了验证编译器整体的复杂性，在每一步验证编译的正确性。另外，还有一种称为可信验证（credible compilation）的技术也是采用类似思路，编译产生转换后的代码的同时，生成额外的上下文信息，使用一个简单的验证器来检查编译步骤的正确性。然而，这些分布验证方法还是无法保证编译器本身是没有缺陷的。

\section{神经网络处理器编译器测试框架的必要性}

\subsection{深度学习指令集的特性}
深度学习指令集(Cambricon)的特性主要是以下几点：

1.采用基于负载存储(load-store)访存模式的RISC指令集。具体指令的选取，根据工作负荷(workload)的类型进行计算层面的抽象得出。对于深层神经网络来说，主要的计算和控制任务有几种：向量计算、矩阵计算、标量计算、分支跳转。其中向量计算、矩阵计算、标量计算都属于标准计算工作，形式上和通用处理器没有什么区别，主要的差别在于细节的支撑上，典型的例子就是应用于漏失(drop-out)的随机向量(Random-Vector)指令，用于在一条指令内部为一个向量进行快速随机初始化，以及应用于激活层的指数向量操作（Vector-Expotential），用于在一条指令内部为一个向量进行快速的非线性变换，而分支跳转的逻辑在神经网络计算任务里，并不像常规计算任务那么复杂，所以指令集的设计上并不需要提供丰富的分支跳转逻辑的支持。

2.不引入复杂的Cache体系和相关控制逻辑。这跟AI算法的workload类型有强关联，对于机器学习算法来说算法来说，数据逻辑性并不强，Cache对性能的影响不像常规计算任务那么大，所以把用于实现cache hierarchy的控制逻辑精简掉，对于提升芯片的计算功耗比会有很大的助益。

3.使用高速暂存存储器(Scratchpad Memory)而不是寄存器堆来作为计算数据的主存储。因为机器学习算法的计算任务与常规的多媒体计算任务不同，指令所操作的数据长度往往是不定长的，所以应用于多媒体指令优化(SIMD)的寄存器堆就不如Scrathpad Memory灵活。

这些特性使得Cambricon指令集能正确的描述现在大部分的网络，同时，每条指令的描述能力高，对于描述同样的网络来说，所需的指令数量相比通用处理器要少很多。但，这也带来了缺陷，即便是同一条指令，对于不同的参数，指令的生存周期变化很大，且需要访问的存储方位也变化很大，不同类型的指令更是如此，更别说设计不同层次的存储访问。

\subsection{神经网络编译器与传统编译器的比较}
由于深度学习指令集的众多特性，这也使得神经网络编译器与传统编译器有很多不同。

首先，神经网络编译器对应编译的指令粒度较大，对于神经网络处理器来说，一条卷积(Conv)指令可以自己设置卷积核的大小、所需要的卷积图像大小，但是传统处理器的指令操作是固定的，这也给我们的验证带来了很多困难。

其次，神经网络编译器和传统编译器设计的存储层次也有很大不同，传统的编译器中，其计算指令都是针对寄存器的操作，只有load或者store才会涉及到寄存器数据和Cache或者RAM之间的数据交互，但神经网络编译器加入了中间存储这一层，改变了整个编译器的存储层次。

\subsection{使用验证框架带来的好处}
由于神经网络编译器的特殊性，若采用随机指令可能无法覆盖到实际使用需求的指令序列，所以需要实际的使用者，也就是编译器生成的指令来做二次检查，来寻找所有网络集合里那些不易覆盖的“Corner Case”。而测试框架是保证编译器和库这一整套系统正确性的环节，不可或缺。

\subsection{本节总结及研究意义}
